{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9471001,"sourceType":"datasetVersion","datasetId":5759570}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 1. Project Overview","metadata":{}},{"cell_type":"markdown","source":"hiiiii","metadata":{}},{"cell_type":"markdown","source":"## Main Objective ","metadata":{}},{"cell_type":"markdown","source":"The objective of this project is to:\n\n* Build a series of regression models using the provided dataset\n* Evaluate and compare different models performance\n* Apply various techniques to improve model accuracy and prevent overfitting.\n\n\nThe focus will be on both **linear** and **nonlinear** regression models. \nIn addition this project will also use **feature selection methods** and **regularization techniques**, followed by **hyperparameter tuning**, to select the optimal model.\n","metadata":{}},{"cell_type":"markdown","source":"## Data Set Description","metadata":{}},{"cell_type":"markdown","source":"This dataset includes around 6,750 rows and 9 columns. Itâ€™s well-suited for Exploratory Data\rAnalysis (EDA) and machine learning tasks, particularly for predictive modeling using\ralgorithms like Linear Regression. \n\nThe main objective of this dataset is to **predict car prices**, making it ideal for developing regression models to understand the relationship between various features and **the target variable (car price)**.\n\n","metadata":{}},{"cell_type":"markdown","source":"The table below describes the dataset columns:\n\n| **Column**         | **Description**                              | **Measurement Level** |\n|---------------------|----------------------------------------------|-----------------------|\n| Car Name           | The name of the car                          | Nominal               |\n| Price              | The price of the car                         | Numeric               |\n| Engine Capacity    | The car engine capacity                      | Numeric               |\n| Cylinder           | The car cylinder power                       | Numeric               |\n| Horse Power        | The car horse power                          | Numeric               |\n| Top Speed          | The car top speed                            | Numeric               |\n| Seats              | Number of seats in the car                   | Numeric               |\n| Brand              | The car brand                                | Nominal               |\n| Country            | The country where the site sells this car    | Nominal               |\n","metadata":{}},{"cell_type":"markdown","source":"# 2. Data Preprocessing ","metadata":{}},{"cell_type":"markdown","source":"## First: Import Dataset","metadata":{}},{"cell_type":"markdown","source":"The code below is responsible for importing data and also displaying quick describtion:","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \ndf=pd.read_csv('/kaggle/input/cars-dataset/cars.csv')\nprint ('successfully imported the dataset')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-22T17:51:50.437079Z","iopub.execute_input":"2024-11-22T17:51:50.437673Z","iopub.status.idle":"2024-11-22T17:51:50.467450Z","shell.execute_reply.started":"2024-11-22T17:51:50.437618Z","shell.execute_reply":"2024-11-22T17:51:50.465955Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T17:51:50.469892Z","iopub.execute_input":"2024-11-22T17:51:50.470404Z","iopub.status.idle":"2024-11-22T17:51:50.513962Z","shell.execute_reply.started":"2024-11-22T17:51:50.470353Z","shell.execute_reply":"2024-11-22T17:51:50.512803Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"In order to understand the data further below we count the number of unique values in each column and their frequency:","metadata":{}},{"cell_type":"code","source":"for col in df.columns:  # Iterate over column names in the DataFrame\n    # Print the name of the column and its type\n    print(f'Name: {col} dtype: {df[col].dtype}\\n')\n    # Print each unique value with its frequency\n    print(f'{df[col].value_counts()}\\n')\n    # Print a separator\n    print(('-' * 100) + '\\n\\n')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T17:51:50.515361Z","iopub.execute_input":"2024-11-22T17:51:50.515654Z","iopub.status.idle":"2024-11-22T17:51:50.540934Z","shell.execute_reply.started":"2024-11-22T17:51:50.515624Z","shell.execute_reply":"2024-11-22T17:51:50.539508Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### What can we notice from each column?\n1. The column car name serves as an identifier and not missing for any of the cars and so no more processing needed.\n2. The price is listed in different currency. Further, some are (TBD, Following, Discountinued), these entries need to be removed for Linear regression because missing target values make it impossible to calculate the error or fit the model properly.\n3. The engine capacity is not standard some are denoted in liters as (1.4, 2.6) and others are in cubic centimeters like (1,400) and these need to be standraized\n4. The cyclinder column has N/A values for electric cars, because the do not have cyclinders and this needs to be handled. Also some are as (Single or Double) that needs to be handled.\n5. the top speed column has some incorrect entries(like 4 Seaters ) and this is incorrect and need to be handled. Further some values are (automatic or N A) and these needs to be addressed.\n6. The seats column has some incorrrect entries , either floats or too large entries like 150.\n7. The brand and country is correctly entered for all.\n","metadata":{}},{"cell_type":"markdown","source":"## Second: Data Cleaning\n\nIn this part we want to perform the following:\n\n\n* Handle missing values\n* Handle incorrect entries or values\n* Encoding categorical features (if applicaple)\n* Normalize or standardize numerical features (if necessary)\n* Split the dataset into: 60% for training, 20% for validation, and 20% for testing\n","metadata":{}},{"cell_type":"markdown","source":"### Handle missing values\n\nWe want to start by removing any missing values from the data set:","metadata":{}},{"cell_type":"code","source":"def remove_missing_price(df):\n    \"\"\"\n    Removes rows where the 'price' column is missing (NaN or contains specific keywords).\n    Displays the number of rows before and after removal.\n    \"\"\"\n    print(f'Rows before removal: {len(df)}')\n\n    # Define missing keywords to check within the 'price' column\n    missing_keywords = ['TBD', 'N A', 'Following', 'DISCONTINUED']\n\n    # Remove rows where 'price' is NaN\n    df = df.dropna(subset=['price'])\n\n    # Remove rows in the 'price' column that contain any of the missing keywords\n    df = df[~df['price'].astype(str).str.contains('|'.join(missing_keywords), case=False, na=False)]\n\n    print(f'Rows after removal: {len(df)}')\n\n    return df\n\n# Apply the function\ndf = remove_missing_price(df)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T17:51:50.542110Z","iopub.execute_input":"2024-11-22T17:51:50.542477Z","iopub.status.idle":"2024-11-22T17:51:50.563103Z","shell.execute_reply.started":"2024-11-22T17:51:50.542441Z","shell.execute_reply":"2024-11-22T17:51:50.561681Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def remove_missing_values(df):\n    \"\"\"\n    Removes rows containing missing keywords and displays the number of rows before and after removal.\n    \"\"\"\n    print(f'Before Removing: {len(df)}')\n\n    # Remove rows with any missing value\n    df.dropna(how='any', inplace=True)\n    \n    # Remove rows with any missing keywords\n    missing_keywords = ['TBD', 'N A', 'Following', 'DISCONTINUED']\n\n    # Remove rows containing any of the missing keywords\n    df = df[~df.apply(lambda row: row.astype(str).str.contains('|'.join(missing_keywords), case=False, na=False).any(), axis=1)]\n\n    print(f'After Removing: {len(df)}')\n\n    return df\n\n\ndf = remove_missing_values(df)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T17:51:50.565972Z","iopub.execute_input":"2024-11-22T17:51:50.566492Z","iopub.status.idle":"2024-11-22T17:51:52.225046Z","shell.execute_reply.started":"2024-11-22T17:51:50.566438Z","shell.execute_reply":"2024-11-22T17:51:52.223811Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Handle incorrect values\n\nHere we want to analyze the colums given insights noted after imoorting and fix any incorrent discrepancies.","metadata":{}},{"cell_type":"markdown","source":"#### Price : \n\nTo ensure consistency, we need to standardize all prices to a common currency, here we'll use USD, for a uniform target variable. This will help avoid discrepancies and improve the accuracy of any predictive modeling","metadata":{}},{"cell_type":"code","source":"def apply_price_adj(price):\n    \"\"\"\n    Converts a price string with a currency code into USD.\n    \"\"\"\n    try:\n        # Extract the currency code (first 3 characters)\n        currency_code = price[:3].strip()\n        # Extract the price string (everything after the currency code) and remove commas\n        price_str = price[4:].replace(',', '').strip()\n        # Convert price to float\n        price_value = float(price_str)\n\n        # Currency conversion rates as of 20 Nov 2024\n        conversion_rates = {\n            'AED': 0.27,   # 1 AED = 0.27 USD\n            'KWD': 3.28,   # 1 KWD = 3.28 USD\n            'OMR': 2.60,   # 1 OMR = 2.60 USD\n            'BHD': 2.65,   # 1 BHD = 2.65 USD\n            'QAR': 0.25,   # 1 QAR = 0.25 USD\n            'SAR': 0.27,   # 1 SAR = 0.27 USD\n            'EGP': 0.021   # 1 EGP = 0.021 USD\n        }\n\n        # Convert to USD if the currency code is valid\n        if currency_code in conversion_rates:\n            price_in_dollars = price_value * conversion_rates[currency_code]\n            return round(price_in_dollars, 3)  # Round to three decimal places\n        else:\n            # Return NaN if the currency code is not recognized\n            return float('nan')\n\n    except (ValueError, IndexError):\n        # Return NaN for invalid input or parsing errors\n        return float('nan')\n\n\n\n# Apply the function to replace the 'price' column values \ndf['price'] = df['price'].apply(apply_price_adj)\n\n# Drop rows where 'price' is NaN\ndf.dropna(subset=['price'], inplace=True)\n\n# Save the cleaned DataFrame to a CSV file\ndf.to_csv('/kaggle/working/output3.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T17:51:52.226347Z","iopub.execute_input":"2024-11-22T17:51:52.226676Z","iopub.status.idle":"2024-11-22T17:51:52.274049Z","shell.execute_reply.started":"2024-11-22T17:51:52.226621Z","shell.execute_reply":"2024-11-22T17:51:52.272536Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Engine Capacity :\nTo ensure consistency, we need to standardize all engine capacities to liters and see we would need to convernt any valus in cubic centimerts to litres.","metadata":{}},{"cell_type":"code","source":"def apply_engine_adj(capacity):\n    \"\"\"\n    Standardizes engine capacity to liters.\n    If the value is greater than 1000, it is assumed to be in cubic centimeters (cc) and converted to liters.\n    Otherwise, it is treated as already in liters.\n    \"\"\"\n    try:\n        # Convert to float for comparison\n        engine_capacity = float(capacity)\n\n        # Check if the value is larger than 1000\n        if engine_capacity > 1000:\n            engine_capacity = engine_capacity / 1000  # Convert cc to liters\n        return round(engine_capacity, 2)  # Return value in liters, rounded to 2 decimals\n\n    except (ValueError, TypeError):\n        # Return NaN for invalid input or parsing errors\n        return float('nan')\n\n\n# Apply the function to replace the 'engine' column values \ndf['engine_capacity'] = df['engine_capacity'].apply(apply_engine_adj)\n\n# Drop rows where 'price' is NaN\ndf.dropna(subset=['engine_capacity'], inplace=True)\n\n# Save the cleaned DataFrame to a CSV file\ndf.to_csv('/kaggle/working/output4.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T17:51:52.275622Z","iopub.execute_input":"2024-11-22T17:51:52.275972Z","iopub.status.idle":"2024-11-22T17:51:52.316386Z","shell.execute_reply.started":"2024-11-22T17:51:52.275936Z","shell.execute_reply":"2024-11-22T17:51:52.315174Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Cylinder:\nWe will apply feature extranction here, for electric cars there is no cylinders , so we will add a column to mark if electric or not. In the cylider column if electric we will set to -1.\n\n","metadata":{}},{"cell_type":"markdown","source":"**Why -1 ?**\n\nFor most vehicles, cylinder counts are typically 3, 4, 6, 8, 10 or 12, using a negative value does not overlap with valid cylinder counts (e.g., 3, 4, 6, 8, etc.).\nIt explicitly indicates the absence of a conventional cylinder count, making it interpretable as \"no cylinders.\"","metadata":{}},{"cell_type":"code","source":"def apply_cylinder_adj(capacity):\n    \"\"\"\n    Adjusts the cylinder values. If the value is 'Electric' or 'N/A', it returns -1.\n    \"\"\"\n    try:\n        # Handle Electric and N/A cases\n        if capacity in ['N/A, Electric']:\n            return -1\n          # Return numeric values as they are\n        return float(capacity)\n    except (ValueError, TypeError):\n        # Return NaN for invalid inputs\n        return float('nan')\n\n# Apply the function to adjust the 'cylinder' column\ndf['cylinder'] = df['cylinder'].apply(apply_cylinder_adj)\n\n# Add a new column to indicate if the vehicle is electric\ndf['is_electric'] = df['cylinder'].apply(lambda x: 1 if x == -1 else 0)\n\n# Save the cleaned DataFrame to a CSV file\ndf.to_csv('/kaggle/working/output5.csv', index=False)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T17:51:52.317744Z","iopub.execute_input":"2024-11-22T17:51:52.318069Z","iopub.status.idle":"2024-11-22T17:51:52.357911Z","shell.execute_reply.started":"2024-11-22T17:51:52.318036Z","shell.execute_reply":"2024-11-22T17:51:52.356940Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Horse Power:\n\nReplace Single, Double, Triple with their standard values","metadata":{}},{"cell_type":"code","source":"def apply_horse_adj(capacity):\n    \"\"\"\n    Adjusts the horsepower values. If the value matches 'Single', 'Double', or 'Triple',\n    it replaces them with their corresponding horsepower values These values are averages taken from online sources. \n    Otherwise, numeric values remain unchanged.\n    \"\"\"\n    horsepower_dict = {\n        'Single': 283,\n        'Double': 422.0,\n        'Triple': 810.0\n    }\n    \n    try:\n        return float(capacity)\n    except (ValueError, TypeError): # if not already numeric\n        # Map known strings to their corresponding horsepower values\n        return horsepower_dict.get(capacity, float('nan'))  # NaN for unrecognized strings\n\n# Apply the function to adjust the 'horse_power' column\ndf['horse_power'] = df['horse_power'].apply(apply_horse_adj)\n\n# Drop rows with NaN in 'horse_power' (invalid entries)\ndf.dropna(subset=['horse_power'], inplace=True)\n\n# Save the cleaned DataFrame to a CSV file\ndf.to_csv('/kaggle/working/output6.csv', index=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T17:51:52.360707Z","iopub.execute_input":"2024-11-22T17:51:52.361085Z","iopub.status.idle":"2024-11-22T17:51:52.403573Z","shell.execute_reply.started":"2024-11-22T17:51:52.361049Z","shell.execute_reply":"2024-11-22T17:51:52.402422Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Speed:\n\nRemove any non-numeric values.","metadata":{}},{"cell_type":"code","source":"def apply_top_speed_adj(speed):\n    \"\"\"\n    Cleans and standardizes the top_speed values.\n    If the value is non-numeric (e.g., 'N/A', 'Unknown'), it is converted to NaN.\n    Otherwise, it is treated as a valid numeric value.\n    \"\"\"\n    try:\n        # Attempt to convert the value to a float\n        return float(speed)\n    except (ValueError, TypeError):\n        # Return NaN for invalid input or parsing errors\n        return float('nan')\n\n\n# Apply the function to replace the 'top_speed' column values\ndf['top_speed'] = df['top_speed'].apply(apply_top_speed_adj)\n\n# Drop rows where 'top_speed' is NaN\ndf.dropna(subset=['top_speed'], inplace=True)\n\n# Save the cleaned DataFrame to a CSV file\ndf.to_csv('/kaggle/working/output7.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T17:51:52.404869Z","iopub.execute_input":"2024-11-22T17:51:52.405238Z","iopub.status.idle":"2024-11-22T17:51:52.445978Z","shell.execute_reply.started":"2024-11-22T17:51:52.405203Z","shell.execute_reply":"2024-11-22T17:51:52.444872Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Seats:\n\nWe need to extract seats into their numeric values:\n\nNote : reaching this here some values that were already invalid like floats (1.4, 2.5) and large values (150), were already removed since there has been multiple issue with that records entry.","metadata":{}},{"cell_type":"code","source":"def apply_seats_adj(seats_string):\n    \"\"\"\n    Extracts the number of seats from a string assuming this format '5 Seater'.\n    \"\"\"\n    try:\n        # Split the string and extract the first part as an integer\n        return int(seats_string.split()[0])\n    except (ValueError, AttributeError, IndexError):\n        # Return NaN for invalid or unparsable values\n        return float('nan')\n\n# Apply the function to the 'seats' column\ndf['seats'] = df['seats'].apply(apply_seats_adj)\n\n# Drop rows where 'seats' is NaN\ndf.dropna(subset=['seats'], inplace=True)\n\n# Save the cleaned DataFrame to a CSV file\ndf.to_csv('/kaggle/working/output8.csv', index=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T17:51:52.447329Z","iopub.execute_input":"2024-11-22T17:51:52.447647Z","iopub.status.idle":"2024-11-22T17:51:52.490588Z","shell.execute_reply.started":"2024-11-22T17:51:52.447615Z","shell.execute_reply":"2024-11-22T17:51:52.489478Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Brand:\n\nWe need to encode Brands.","metadata":{}},{"cell_type":"code","source":"# add code to encode","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T17:51:52.491932Z","iopub.execute_input":"2024-11-22T17:51:52.492458Z","iopub.status.idle":"2024-11-22T17:51:52.497826Z","shell.execute_reply.started":"2024-11-22T17:51:52.492410Z","shell.execute_reply":"2024-11-22T17:51:52.496450Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Country:\n\nWe need to encode Countries.","metadata":{}},{"cell_type":"code","source":"# add code to encode","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T17:51:52.499431Z","iopub.execute_input":"2024-11-22T17:51:52.499879Z","iopub.status.idle":"2024-11-22T17:51:52.511423Z","shell.execute_reply.started":"2024-11-22T17:51:52.499827Z","shell.execute_reply":"2024-11-22T17:51:52.510409Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Summary:\n\nThe current number of records is 4078, the original was 6038. We lost around 35% of the data, we will continue and assume acceptable with that since the data has many issues and descripincies in the start.","metadata":{}},{"cell_type":"code","source":"print (len(df))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T17:51:52.512982Z","iopub.execute_input":"2024-11-22T17:51:52.513424Z","iopub.status.idle":"2024-11-22T17:51:52.526302Z","shell.execute_reply.started":"2024-11-22T17:51:52.513375Z","shell.execute_reply":"2024-11-22T17:51:52.525186Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Encode Categorical\n","metadata":{}},{"cell_type":"markdown","source":"### Normalize Numeric\n","metadata":{}},{"cell_type":"markdown","source":"### Split Data:\n\nA commin split that is used here is 60% for training, 20% for validation, and 20% for testing.\n","metadata":{}},{"cell_type":"code","source":"from sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split\n\n# Shuffle the dataset\ndf_shuffled = shuffle(df, random_state=42) # note that 42 is a widely used convention but can be anything -> this is used for consistent reproducability of the data\n\n# Split the data into training (60%) and temp (40%)\ntrain_data, temp_data = train_test_split(df_shuffled, test_size=0.4, random_state=42)\n\n# Split the temp data into validation and testing \nval_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42)\n\n# Output the sizes of each split to verify\nprint (len(train_data))\nprint (len(val_data))\nprint(len(test_data))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T17:51:52.527626Z","iopub.execute_input":"2024-11-22T17:51:52.527952Z","iopub.status.idle":"2024-11-22T17:51:52.546032Z","shell.execute_reply.started":"2024-11-22T17:51:52.527913Z","shell.execute_reply":"2024-11-22T17:51:52.544892Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Feature Extraction:\n\nCan we ignore some of the features, are they irrelevant?","metadata":{}},{"cell_type":"code","source":"\nf_num = ['price', 'engine_capacity', 'cylinder', 'horse_power', 'top_speed', 'seats']\n\n# Filter the dataset to include only the selected numerical columns\ndataset_corr = df[f_num]\n\n# Compute the correlation matrix\ncorrelation_matrix = dataset_corr.corr()\n\n# Plot the heatmap\nplt.figure(figsize=(10, 8))\nsns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', square=True)\nplt.title('Correlation Heatmap')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T17:51:52.547717Z","iopub.execute_input":"2024-11-22T17:51:52.548190Z","iopub.status.idle":"2024-11-22T17:51:52.899284Z","shell.execute_reply.started":"2024-11-22T17:51:52.548139Z","shell.execute_reply":"2024-11-22T17:51:52.898133Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 3. Building Regression Models ","metadata":{}},{"cell_type":"markdown","source":"## Linear Models","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"## Noninear Models","metadata":{}},{"cell_type":"markdown","source":"# Extra: Exploratory data analysis (EDA) + Interactivity\n\nThis part is inspired by the work from Federico's notebook: \n\"Data Cleaning | EDA\" \nLink: https://www.kaggle.com/code/fede123/data-cleaning-eda\n","metadata":{}}]}